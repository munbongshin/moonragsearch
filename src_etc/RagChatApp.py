from dotenv import load_dotenv
from openai import OpenAI
import streamlit as st
from langchain_openai import ChatOpenAI
from langchain_core.messages import ChatMessage
from langchain_core.documents import Document
from langchain.llms import Ollama
from langchain.prompts import PromptTemplate

from langchain_community.embeddings import OllamaEmbeddings
from langchain_community.llms import LlamaCpp
from langchain.chains.question_answering import load_qa_chain
from langchain_core.embeddings import Embeddings
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.prompts import PromptTemplate
from langchain_chroma import Chroma
from sentence_transformers import SentenceTransformer

import logging, os, platform, base64, time
import  subprocess, requests
from tkinter import Tk, filedialog
# managechromadb0k2.pyì—ì„œ ChromaDBManagerë¥¼ import
from ChromaDbApp import ChromaDBManager
from typing import IO 

MODEL_PATH="C:/Dev/models/ko-sbert-nli"
ARG_TEMP_PATH="c:/tmp"

class CustomOpenAIEmbeddings(Embeddings):
    def __init__(self, client, model_name_or_path=MODEL_PATH):
        self.client = client
        self.model = SentenceTransformer(model_name_or_path)

    def embed_documents(self, texts):
        embeddings = self.client.embeddings.create(model=self.model, input=texts)
        return [embedding.embedding for embedding in embeddings.data]

    def embed_query(self, text):
        embedding = self.client.embeddings.create(model=self.model, input=[text])
        return embedding.data[0].embedding
    
#ì‚¬ìš©ì ì •ì˜ ì„ë² ë”© í´ë˜ìŠ¤ë¥¼ ë§Œë“­ë‹ˆë‹¤:
class CustomSentenceTransformerEmbeddings:
    def __init__(self, model_name_or_path=MODEL_PATH):
        # ë¡œì»¬ ëª¨ë¸ ê²½ë¡œ ì‚¬ìš©
        if os.path.exists(model_name_or_path):
            self.model = SentenceTransformer(model_name_or_path)
        else:
            raise ValueError(f"Model not found at {model_name_or_path}. Please download the model first.")
    
    def embed_documents(self, documents):
        return self.model.encode(documents).tolist()

    def embed_query(self, query):
        return self.model.encode(query).tolist()

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = OpenAI(base_url="http://localhost:1234/v1", api_key="lm-studio")

# ì»¤ìŠ¤í…€ ì„ë² ë”© ê°ì²´ ìƒì„±
#embeddings = CustomOpenAIEmbeddings(client, "heegyu/EEVE-Korean-Instruct-10.8B-v1.0-GGUF")
#embeddings = OllamaEmbeddings(model="mxbai-embed-large:latest")
embeddings = CustomSentenceTransformerEmbeddings(MODEL_PATH)

# LLMì„ ì „ì—­ ë³€ìˆ˜ë¡œ ì´ˆê¸°í™”
lm_llm = ChatOpenAI(
    base_url="http://localhost:1234/v1",
    api_key="lm-studio",
    model="QuantFactory/EEVE-Korean-Instruct-10.8B-v1.0-GGUF",
    streaming=True,
    temperature=0,
)

ola_llm =  Ollama(model="llama3:instruct")

collection_name = "rag_test"
FILLTERED_DOC_NUMBER = 5
BASE_URL = "http://localhost:1234/v1"
DEFAULT_LLMNAME = "QuantFactory/EEVE-Korean-Instruct-10.8B-v1.0-GGUF"
# Prompt template
raw_prompt = PromptTemplate.from_template(
    """
    <s>[INST] Use the following pieces of context to answer the user's question into korean.\n
     If you don't know the answer, just say that you don't know, don't try to make up an answer.\n
     add the summarization of answer at the end of the answer.[/INST]</s>
    [INST] Context: {context}
    Question: {question}
    Answer:
    [/INST]
    """
)


class ChatMessage:
    def __init__(self, role, content):
        self.role = role
        self.content = content

class RAGChatApp:
    def __init__(self):
        load_dotenv()
        self.persist_directory = "c:/DEV/mooland/PDFchatLLM/chroma_db"
        self.collection_name = "rag_test"
        self.db_manager = ChromaDBManager(persist_directory=self.persist_directory)
        self.llm = lm_llm
        self.initialize_session_state()
        os.environ["POSTHOG_DISABLED"] = "1"
        
        
    def get_ollama_models(self):
        result = subprocess.run(['ollama', 'list'], capture_output=True, text=True)
        lines = result.stdout.strip().split('\n')[1:]  # ì²« ì¤„(í—¤ë”)ì„ ì œì™¸
        models = [line.split()[0] for line in lines]  # ëª¨ë¸ ì´ë¦„ë§Œ ì¶”ì¶œ
        return models
    
    def get_lm_studio_models(self, base_url):
        try:
            response = requests.get(f"{base_url}/model", timeout=5)  # 5ì´ˆ íƒ€ì„ì•„ì›ƒ ì¶”ê°€
            if response.status_code == 200:
                model_info = response.json()
                # 'id' í•„ë“œê°€ ìˆë‹¤ë©´ ê·¸ê²ƒì„ ì‚¬ìš©í•˜ê³ , ì—†ë‹¤ë©´ ì „ì²´ ì‘ë‹µì„ ë¬¸ìì—´ë¡œ ë°˜í™˜
                model_name = model_info.get('id', str(model_info))
                return model_name  # ë¬¸ìì—´ë¡œ ë°˜í™˜
            else:
                st.error(f"LM Studio ì„œë²„ ì‘ë‹µ ì˜¤ë¥˜: {response.status_code}")
                return DEFAULT_LLMNAME
        except requests.RequestException as e:
            if "NewConnectionError" in str(e):
                st.error(f"LM Studio ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
            elif "ConnectTimeoutError" in str(e):
                st.error(f"LM Studio ì„œë²„ ì—°ê²° ì‹œê°„ ì´ˆê³¼. ì„œë²„ ì£¼ì†Œì™€ í¬íŠ¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
            else:
                st.error(f"LM Studio ì„œë²„ ì—°ê²° ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
            st.error(f"ìƒì„¸ ì˜¤ë¥˜: {e}")
            return DEFAULT_LLMNAME
           
    def set_llm_model(self, modelname):
        self.llm = modelname

    def initialize_session_state(self):
        if "messages" not in st.session_state:
            st.session_state.messages = []
        if "docs" not in st.session_state:
            st.session_state.docs = None
        if "selected_sources" not in st.session_state:
            st.session_state.selected_sources = []
        if "last_query" not in st.session_state:
            st.session_state.last_query = ""
        if "rag_usage" not in st.session_state:
            st.session_state.rag_usage = "Rag+LLM"
        if "max_docnum" not in st.session_state:
            st.session_state.max_docnum = 3
        if "apply_filter" not in st.session_state:
            st.session_state.apply_filter = False
        if "filtered_sources" not in st.session_state:
            st.session_state.filtered_sources = []
        if "Rag+LLM" not in st.session_state:    
            st.session_state.RagUsage = "Rag+LLM"
            
    def set_collection_name(self, ragname):
        self.collection_name = ragname
            
    def parse_input(self, input_text):
        # ì…ë ¥ ë¬¸ìì—´ì„ ë¶„ë¦¬
        parts = input_text.split(']', 1)
        
        if len(parts) > 1 and parts[0].startswith('['):
            # ì˜ˆì•½ì–´ê°€ ìˆëŠ” ê²½ìš°
            keyword = parts[0][1:].strip().lower()  # '[' ì œê±° ë° ì†Œë¬¸ì ë³€í™˜
            query = parts[1].strip()
            return keyword, query
        else:
            # ì˜ˆì•½ì–´ê°€ ì—†ëŠ” ê²½ìš°
            return None, input_text.strip()
    
    def filter_results_by_score(results, threshold=400):
        """
        results ë¦¬ìŠ¤íŠ¸ì—ì„œ scoreê°€ threshold ì´í•˜ì¸ í•­ëª©ë§Œ í•„í„°ë§í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.
        
        :param results: ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸. ê° í•­ëª©ì€ 'score' í‚¤ë¥¼ í¬í•¨í•˜ëŠ” ë”•ì…”ë„ˆë¦¬ì—¬ì•¼ í•©ë‹ˆë‹¤.
        :param threshold: í•„í„°ë§í•  scoreì˜ ì„ê³„ê°’. ê¸°ë³¸ê°’ì€ 400ì…ë‹ˆë‹¤.
        :return: í•„í„°ë§ëœ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
            """
        filtered_results = [item for item in results if item.get('score', float('inf')) <= threshold]
        return filtered_results
    
    def perform_search(self,query, db_manager, collection_name, selected_sources=None):
        raw_results = db_manager.search_collection(collection_name, query, n_results=FILLTERED_DOC_NUMBER,inscore=350)
        
        if not raw_results:
            return []  # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
        
        # ê²°ê³¼ë¥¼ Document ê°ì²´ë¡œ ë³€í™˜í•˜ê³  ê´€ë ¨ë„ ì ìˆ˜ì— ë”°ë¼ ì •ë ¬
        docs = [
            Document(
                page_content=result['page_content'],
                metadata={"score": result['score'], **result['metadata']}
            )
            for result in raw_results
        ]
        
        
        #docs.sort(key=lambda x: x.metadata['score'], reverse=False)
        
        #threshold = 500
        #filtered_docs = [doc for doc in docs if doc.metadata['score'] <= threshold]
        filtered_docs = [doc for doc in docs]
        logging.basicConfig(level=logging.INFO)
        logger = logging.getLogger(__name__)
        logger.info("Starting Perform Search")
        logger.info(f"filtered Doc: {filtered_docs}")
        if selected_sources:
            filtered_docs = [doc for doc in filtered_docs if doc.metadata.get('source', 'Unknown') in selected_sources]
        
        return filtered_docs


    def setup_ui(self):
        st.set_page_config(page_title="AIì—ê²Œ ì§ˆë¬¸í•˜ê¸°", layout="wide")
        st.header("Ask your PDF, DOC, PPT, Excel, HWP ğŸ’¬")
        
        # ë©”ì¸ ì»¨í…ì¸  ì˜ì—­ ìƒì„±
        main_content = st.empty()
        
        # ë©”ì¸ ì»¨í…ì¸  ì•ˆì— ë‘ ê°œì˜ ì»¬ëŸ¼ ìƒì„±
        # ë‘ ê°œì˜ ì»¬ëŸ¼ ìƒì„±
        global maincol1, maincol2
        with main_content.container():
            maincol1, maincol2 = st.columns([7, 3])  # 7:3 ë¹„ìœ¨ë¡œ ë¶„í• 

            
    def setup_sidebar(self):
        with st.sidebar:
            st.header("Rag Menu")
            
            # íƒ­ ìƒì„±
            tab1, tab2, tab3, tab4 = st.tabs(["Arg Chat","ì„ë² ë”©", "ChromaDB ê´€ë¦¬","LLM ëª¨ë¸"])
            
            with tab1:                
                self.setup_arg_chat_tab()
            
            with tab2:
                self.setup_embed_page()
            
            with tab3:                
                self.setup_chromadb_tab()
                
            with tab4:                
                self.setup_llmmodel_page()
        
    def setup_arg_chat_tab(self):
        st.header("Arg Chat")
        #st.session_state.max_docnum = st.number_input("ì°¸ì¡°ë¬¸ì„œ ìˆ˜ ì…ë ¥", max_value=20, min_value=3, step=1, value=st.session_state.max_docnum)
        st.session_state.rag_usage = st.radio("Ragì´ìš©ì—¬ë¶€ ğŸ‘‡", ["Rag+LLM", "LLM"], index=0 if st.session_state.rag_usage == "Rag+LLM" else 1)
        collections = self.db_manager.list_collections()
        selected_collection = st.selectbox("ê²€ìƒ‰í•  ì»¬ë ‰ì…˜ì„ ì„ íƒí•˜ì„¸ìš”", collections, key="search_collection_name")
        self.set_collection_name(selected_collection)
        self.setup_document_selection(selected_collection)
        
    def display_search_results(self, results):
        with maincol2:
            if not results:
                st.write("No results found.")
            else:
                for i, result in enumerate(results, 1):
                    key = "view_" + str(i)
                    with st.expander(f"Result {i}"):
                        if isinstance(result, dict):
                            st.write(f"**Content:** {result['page_content']}")
                            st.write(f"**Metadata:** {result['metadata']}")
                            st.write(f"**Score:** {result['score']:.1f}")
                            if st.button(f"**File_name:** {result['metadata']['file_name']}", key=key):
                                # íŒŒì¼ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ê¸°ëŠ¥ êµ¬í˜„                        
                                #self.open_file_in_streamlit(result['original_file']['filename'])
                                self.show_pdf(result['metadata']['file_name'])
                        else:
                            st.write(f"**Content:** {result.page_content}")
                            st.write(f"**Metadata:** {result.metadata}")
                            st.write(f"**Score:** {result.metadata.get('score'):.1f}")
                            # íŒŒì¼ ì´ë¦„ì„ í´ë¦­í•˜ë©´ í•´ë‹¹ ë¬¸ì„œë¥¼ ë¶ˆëŸ¬ì˜¤ê¸°
                            if st.button(f"**File_name:** {result.metadata.get('file_name')}", key=key):
                                # íŒŒì¼ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ê¸°ëŠ¥ êµ¬í˜„                        
                                #self.open_file_in_streamlit(result['original_file']['filename'])
                                self.show_pdf(result.metadata.get('file_name'))
                        
    def show_pdf(self, file_path):
        logging.basicConfig(level=logging.INFO)
        st.write("ë¡œê¹… í…ŒìŠ¤íŠ¸")
        logging.info("ì´ ë©”ì‹œì§€ê°€ ì½˜ì†”ì— í‘œì‹œë˜ì–´ì•¼ í•©ë‹ˆë‹¤.")
        st.set_option('client.showErrorDetails', True)
        placeholder = st.empty()
        placeholder.text("ì´ í…ìŠ¤íŠ¸ê°€ ë³´ì´ë‚˜ìš”?")
        file_path = os.path.join(self.persist_directory,file_path)
        with open(file_path,"rb") as f:
            base64_pdf = base64.b64encode(f.read()).decode('utf-8')
        pdf_display = f'<iframe src="data:application/pdf;base64,{base64_pdf}" width="800" height="800" type="application/pdf"></iframe>'
        st.markdown(pdf_display, unsafe_allow_html=True)
    
    def open_file_in_streamlit(self, file_path):
        file_path = os.path.join(self.persist_directory,file_path)
        if os.path.exists(file_path):
            file_extension = os.path.splitext(file_path)[1].lower()
            supported_extensions = ['.pdf', '.doc', '.docx', '.hwp','.pptx','.ppt','.xls','.xlsx']
            
            if file_extension in supported_extensions:
                try:
                    if platform.system() == 'Windows':
                        os.startfile(file_path)
                        st.success(f"{file_path} íŒŒì¼ì´ ê¸°ë³¸ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ì—´ë ¸ìŠµë‹ˆë‹¤.")
                    else:
                        st.error("ì´ ê¸°ëŠ¥ì€ Windowsì—ì„œë§Œ ì§€ì›ë©ë‹ˆë‹¤.")
                except Exception as e:
                    st.error(f"íŒŒì¼ì„ ì—´ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {str(e)}")
            else:
                st.warning(f"ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤: {file_extension}")
                st.write("ì§€ì›ë˜ëŠ” íŒŒì¼ í˜•ì‹: .pdf, .doc, .docx, .hwp")
        else:
            st.error(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
                        
    def list_files_in_directory(self, directory):
        files = []
        for file in os.listdir(directory):
            if os.path.isfile(os.path.join(directory, file)):
                files.append(file)
        return files

    def setup_document_selection(self,collection_name):
        st.subheader("ê²€ìƒ‰ëŒ€ìƒ ë¬¸ì„œì„ íƒ")
        
        # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
        if 'filtered_sources' not in st.session_state:
            st.session_state.filtered_sources = []
        if 'selected_sources' not in st.session_state:
            st.session_state.selected_sources = []
        if 'show_search_results' not in st.session_state:
            st.session_state.show_search_results = False
        if 'apply_filter' not in st.session_state:
            st.session_state.apply_filter = False

        # ê²€ìƒ‰ ì…ë ¥ í•„ë“œ
        source_search = st.text_input("ë¬¸ì„œê²€ìƒ‰:", key="source_search_input")
        
        # ê²€ìƒ‰ ë²„íŠ¼ ê²€ìƒ‰ì–´ê°€ ì—†ìœ¼ë©´ ëª¨ë“  íŒŒì¼ëª…ì„ ë°˜í™˜í•¨
        if st.button("ê²€ìƒ‰"):
            st.session_state.filtered_sources = self.db_manager.get_all_documents_source(collection_name, source_search)
            st.session_state.show_search_results = True
        
        # ê²€ìƒ‰ ê²°ê³¼ë¥¼ ëŒ€í™”ìƒì í˜•íƒœë¡œ í‘œì‹œ
        if st.session_state.show_search_results:
            with st.expander("ê²€ìƒ‰ ê²°ê³¼", expanded=True):
                st.write("ë‹¤ìŒ ë¬¸ì„œë“¤ì´ ê²€ìƒ‰ë˜ì—ˆìŠµë‹ˆë‹¤. ì„ íƒí•˜ì„¸ìš”:")
                for source in st.session_state.filtered_sources:
                    if st.checkbox(source, key=f"check_{source}"):
                        if source not in st.session_state.selected_sources:
                            st.session_state.selected_sources.append(source)
                    elif source in st.session_state.selected_sources:
                        st.session_state.selected_sources.remove(source)                
                if st.button("ì„ íƒ ì™„ë£Œ"):
                    st.session_state.show_search_results = False
                    
        
        # ì„ íƒëœ ë¬¸ì„œ í‘œì‹œ
        selected = st.multiselect(
            "ì„ íƒëœ ë¬¸ì„œ:", 
            options=st.session_state.filtered_sources,
            default=st.session_state.selected_sources,
            key="final_selected_sources",
        )
        
        # multiselectì˜ ê²°ê³¼ë¡œ selected_sources ì—…ë°ì´íŠ¸
        st.session_state.selected_sources = selected
        
        col1, col2 = st.columns(2)
        with col1: 
            st.session_state.apply_filter = st.checkbox("ì ìš©", value=st.session_state.apply_filter)
        with col2:
            if st.button("í•„í„° ì´ˆê¸°í™”"):
                st.session_state.selected_sources = []
                st.session_state.filtered_sources = []
                st.session_state.apply_filter = False
                
        pass
            
    def setup_chromadb_tab(self):
        st.title("Arg Searchë¥¼ ìœ„í•œ ChromaDB ê´€ë¦¬ Section")
        # get_collection_name ë©”ì„œë“œ í˜¸ì¶œ
        
        management_menu = st.selectbox(
        "ì‘ì—…ì„ ì„ íƒí•˜ì„¸ìš”",
        ("Collection ìƒì„±", "Collection ì‚­ì œ", "Collection ë‚´ìš©ê²€ìƒ‰","Collection ë‚´ìš©ë³´ê¸°"), key="tabmenu_select"
        )
        collections = self.db_manager.get_list_collections()
        if not isinstance(collections, (list, tuple)):
            st.error("ì»¬ë ‰ì…˜ ëª©ë¡ì„ ê°€ì ¸ì˜¤ëŠ” ë° ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
            return
        if management_menu == "Collection ìƒì„±":
            st.header("ìƒˆ ì»¬ë ‰ì…˜ ìƒì„±")
            collection_name = st.text_input("ìƒì„±í•  ì»¬ë ‰ì…˜ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”")                
            if st.button("ìƒì„±", key="create_new_collection"):
                # ì—¬ê¸°ì— ChromaDB ì»¬ë ‰ì…˜ ìƒì„± ë¡œì§ ì¶”ê°€
                # collection_nameì´ collectionsì— ìˆëŠ”ì§€ í™•ì¸
                if collection_name not in collections:
                    result = self.db_manager.create_collection(collection_name)
                    st.info(f"ì»¬ë ‰ì…˜ '{result}'ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
                else:
                    st.info(f"ì»¬ë ‰ì…˜ '{collection_name}'ì´ ì¡´ì¬í•˜ì—¬ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        elif management_menu == "Collection ì‚­ì œ":
            st.header("ì»¬ë ‰ì…˜ ì‚­ì œ")
            # ìƒíƒœ ì´ˆê¸°í™”
            if 'delete_state' not in st.session_state:
                st.session_state.delete_state = 'initial'

            selected_collection = st.selectbox("ì‚­ì œí•  ì»¬ë ‰ì…˜ì„ ì„ íƒí•˜ì„¸ìš”", collections, key="delete_collection_select")

            if st.session_state.delete_state == 'initial':
                if st.button("ì‚­ì œ", key="delete_collection"):
                    st.session_state.delete_state = 'confirm'
                    
            elif st.session_state.delete_state == 'confirm':
                st.write(f"'{selected_collection}' ì»¬ë ‰ì…˜ì„ ì‚­ì œí•˜ì‹œê² ìŠµë‹ˆê¹Œ?")
                col1, col2 = st.columns(2)
                with col1:
                    if st.button("ì˜ˆ", key="confirm_yes"):
                        # ì‚­ì œ ë¡œì§ ì‹¤í–‰
                        result = self.db_manager.delete_collection(selected_collection)
                        st.success(f"'{selected_collection}' ì»¬ë ‰ì…˜ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
                        st.session_state.delete_state = 'initial'
                        
                with col2:
                    if st.button("ì•„ë‹ˆì˜¤", key="confirm_no"):
                        st.info("ì‚­ì œê°€ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                        st.session_state.delete_state = 'initial'
                        
        elif management_menu == "Collection ë‚´ìš©ê²€ìƒ‰":
            st.header("ì»¬ë ‰ì…˜ ê²€ìƒ‰")
            #collections = self.db_manager.list_collections()
            # ì»¬ë ‰ì…˜ì´ ë¦¬ìŠ¤íŠ¸ë‚˜ íŠœí”Œ í˜•íƒœì¸ì§€ í™•ì¸
            selected_collection = st.selectbox("ê²€ìƒ‰í•  ì»¬ë ‰ì…˜ì„ ì„ íƒí•˜ì„¸ìš”", collections, key="search_collection_select")
        
            search_query = st.text_input("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”")
            if st.button("ê²€ìƒ‰", key="search_collection_content"):
                # ì—¬ê¸°ì— ê²€ìƒ‰ ë¡œì§ ì¶”ê°€
                results = self.db_manager.search_collection(selected_collection, search_query,self.db_manager.docnum,inscore=350)                
                self.display_search_results(results)                
        elif management_menu == "Collection ë‚´ìš©ë³´ê¸°":
            st.header("ì»¬ë ‰ì…˜ ë‚´ìš©ë³´ê¸°")
            collections = self.db_manager.list_collections()       
            selected_collection = st.selectbox("ì»¬ë ‰ì…˜ì„ ì„ íƒí•˜ì„¸ìš”", collections,  key="view_collection_select")            
            if st.button("ë‚´ìš© ë³´ê¸°", key="view_collection_content"):
                # ì—¬ê¸°ì— ì„ íƒëœ ì»¬ë ‰ì…˜ì˜ ë‚´ìš©ì„ í‘œì‹œí•˜ëŠ” ë¡œì§ ì¶”ê°€
                content = self.db_manager.view_collection_content(selected_collection)
                st.write(f"'{selected_collection}'ì˜ ë‚´ìš©ì…ë‹ˆë‹¤.")
                st.markdown(content)
    
    def select_folder(self):
        root = Tk()
        root.withdraw()  # Tk ì°½ ìˆ¨ê¸°ê¸°
        folder_path = filedialog.askdirectory()
        root.destroy()
        return folder_path
    
    def save_file_to_ragtmp_directory(file, filename):
        # ragtmp ë””ë ‰í† ë¦¬ ê²½ë¡œ ì„¤ì •
        ragtmp_dir = os.path.join(os.getcwd(), 'ragtmp')

        # ragtmp ë””ë ‰í† ë¦¬ê°€ ì—†ëŠ” ê²½ìš°ì—ë§Œ ìƒì„±
        if not os.path.exists(ragtmp_dir):
            os.makedirs(ragtmp_dir)

        # íŒŒì¼ì„ ragtmp ë””ë ‰í† ë¦¬ì— ì €ì¥
        file_path = os.path.join(ragtmp_dir, filename)
        with open(file_path, 'wb') as f:
            f.write(file.getbuffer())

        # ë””ë ‰í† ë¦¬ì™€ íŒŒì¼ ì´ë¦„ì„ ê²°í•©í•˜ì—¬ ê°’ ë°˜í™˜
        return file_path

    def delete_file(file_path):
        try:
            os.remove(file_path)
            return True
        except FileNotFoundError:
            st.warning("íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        
    def setup_llmmodel_page(self):
        st.title("LLM ëª¨ë¸ ì±—ë´‡")

        # LLM ì†ŒìŠ¤ ì„ íƒ
        llm_source = st.radio("LLM ì†ŒìŠ¤ ì„ íƒ:", ("LM Studio", "Ollama"))

        if llm_source == "Ollama":
            models = self.get_ollama_models()
            
            if not models:
                st.error("ì‚¬ìš© ê°€ëŠ¥í•œ Ollama ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. 'ollama pull' ëª…ë ¹ì–´ë¡œ ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œ í•´ì£¼ì„¸ìš”.")
                self.set_llm_model(lm_llm)
                return 

            selected_model = st.selectbox("ì‚¬ìš©í•  Ollama ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”:", models)
            st.write(f"ì„ íƒí•œ ëª¨ë¸: {selected_model}")

            # Ollama ëª¨ë¸ ì´ˆê¸°í™”
            llm = Ollama(model=selected_model)
            self.set_llm_model(llm)
        else:  # LM Studio
            models = self.get_lm_studio_models(BASE_URL)       
            
            if models:
                lm_llm.model_name = models
                self.set_llm_model(lm_llm)
                st.success("LM Studio ì„œë²„ì— ì„±ê³µì ìœ¼ë¡œ ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤.")
            else:
                self.set_llm_model(lm_llm)
                st.error("LM Studio ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë””í´íŠ¸ ì…‹íŒ…ì„ ë”°ë¦…ë‹ˆë‹¤.")


    def setup_embed_page(self):
        st.header("ì„ë² ë”©")         
        collections = self.db_manager.list_collections()       
        selected_collection = st.selectbox("ì»¬ë ‰ì…˜ì„ ì„ íƒí•˜ì„¸ìš”", collections, key="embed_collection_select")
        collection_name = selected_collection

        # ì´ˆê¸°í™” ë²„íŠ¼
        if st.button("íŒŒì¼ ì—…ë¡œë” ì´ˆê¸°í™”"):
            st.session_state.files_processed = False
            st.experimental_rerun()

        # íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ í”Œë˜ê·¸ í™•ì¸
        if 'files_processed' not in st.session_state:
            st.session_state.files_processed = False

        # íŒŒì¼ ì—…ë¡œë”ë¥¼ ì¡°ê±´ë¶€ë¡œ í‘œì‹œ
        if not st.session_state.files_processed:
            uploaded_files = st.file_uploader("íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”", type=['.pdf','.pptx','.ppt', '.doc', '.docx','.hwp','.hwpx','.xlsx'], accept_multiple_files=True)
            
            if st.button("ë²¡í„°ì €ì¥", key="store_vector_collection"):            
                if uploaded_files is not None:                
                    total_chunks_stored = 0
                    for file in uploaded_files:
                        try:
                            # í…ìŠ¤íŠ¸ ì¶”ì¶œ                
                            with st.spinner(f"{file.name} íŒŒì¼ì˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘..."):
                                text = self.db_manager.extract_text_from_file(file, file.name)
                            
                            if not text:
                                st.warning(f"{file.name}ì—ì„œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
                                continue

                            # í…ìŠ¤íŠ¸ ì²˜ë¦¬ ë° ì„ë² ë”©
                            with st.spinner(f"{file.name} í…ìŠ¤íŠ¸ ì²˜ë¦¬ ë° ì„ë² ë”© ì¤‘..."):
                                processed_text = text  # í•„ìš”í•œ ê²½ìš° ì „ì²˜ë¦¬ ë¡œì§ ì¶”ê°€
                                chunks_stored = self.db_manager.split_embed_docs_store(processed_text, file.name, collection_name)
                            
                            total_chunks_stored += chunks_stored
                            st.success(f"'{file.name}' íŒŒì¼ì´ ì²˜ë¦¬ë˜ì–´ {chunks_stored}ê°œì˜ ì²­í¬ê°€ '{collection_name}' ì»¬ë ‰ì…˜ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                        except Exception as e:
                            st.error(f"{file.name} íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                    
                    # ëª¨ë“  íŒŒì¼ ì²˜ë¦¬ê°€ ì™„ë£Œëœ í›„
                    st.success(f"ì´ {total_chunks_stored}ê°œì˜ ì²­í¬ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    st.session_state.files_processed = True
                    st.experimental_rerun()
        else:
            st.success("íŒŒì¼ ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ìƒˆ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë ¤ë©´ 'íŒŒì¼ ì—…ë¡œë” ì´ˆê¸°í™”' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")
                
       

   
    def handle_user_input(self):
        with maincol1:
            user_question = st.chat_input("Enter your search query")
            if user_question:
                st.chat_message("user").markdown(user_question)
                st.session_state.messages.append(ChatMessage(role="user", content=user_question))
                st.session_state.last_query = user_question
                self.process_query(user_question)


    def process_query(self, query):
        keyword, parsed_query = self.parse_input(query)
        if (keyword == "f" or st.session_state.apply_filter) and st.session_state.rag_usage == "Rag+LLM":
            self.process_filtered_query(parsed_query)
        else:
            self.process_regular_query(parsed_query)

    def process_filtered_query(self, query):
        if st.session_state.selected_sources:
            docs = self.db_manager.get_documents_by_source(self.collection_name, st.session_state.selected_sources)
            if docs:
                self.generate_response(docs, query)
            else:
                st.write("No documents found for the selected sources.")
        else:
            st.info("ê²€ìƒ‰í•  ë¬¸ì„œë¥¼ ì„ íƒí•˜ì„¸ìš”!")

    def process_regular_query(self, query):
        if st.session_state.RagUsage == "Rag+LLM":
            with st.spinner('Rag+LLM ë‹µë³€ ì‚¬ì „ ì¤€ë¹„ì¤‘...'):
                docs = self.perform_search(query, self.db_manager, self.collection_name, st.session_state.selected_sources)                
            if docs:
                self.generate_response(docs, query)                
                self.display_search_results(docs)
            else:
                self.fallback_to_llm(query)
        else:
            self.generate_response(None, query)

    def generate_response(self, docs, query):
        try:
            chain = load_qa_chain(self.llm, chain_type="stuff", verbose=True)
            with maincol1:
                with st.spinner('AI ë‹µë³€ì„ ê¸°ë‹¤ë¦¬ê³  ìˆëŠ”ì¤‘...'):
                    response = chain.run(input_documents=docs or "", question=query)
                    with st.chat_message("assistant"):
                        st.markdown(response)
                    st.session_state.messages.append(ChatMessage(role="assistant", content=response))
        except Exception as e:
            st.error(f"LLM ì„œë²„ì—°ê²° ì˜¤ë¥˜ ë°œìƒ: {e}")

    def fallback_to_llm(self, query):
        st.info("ì„ íƒí•œ ì†ŒìŠ¤ë‚˜ ë¬¸ì„œì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ LLMì— ì§ˆì˜í•©ë‹ˆë‹¤.")
        self.generate_response(None, query)
     

    def run(self):
        self.setup_ui()
    
        # ì‚¬ì´ë“œë°” ì„¤ì •
        with st.sidebar:
            self.setup_sidebar()
        
        # ë©”ì¸ ì˜ì—­
        self.handle_user_input()


if __name__ == '__main__':
    app = RAGChatApp()
    app.run()
