from dotenv import load_dotenv, set_key
from pathlib import Path
import streamlit as st
import sys, platform
import asyncio
from langchain_core.messages import ChatMessage
from langchain_core.documents import Document
#from langchain.llms import Ollama
from langchain.chains.question_answering import load_qa_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from sentence_transformers import SentenceTransformer
import os, base64, time
import subprocess, requests
from langchain_community.llms import Ollama
from langchain_groq import ChatGroq  #pip install langchain-groq
from langchain_openai import ChatOpenAI
from TextSummarizer import TextSummarizer #by mbs
from GroqManager import  GroqManager
from GroqManager import get_groq_response as GroqResponse
from ChromaDbManager import ChromaDbManager
from CustomSentenceTransformerEmbeddings import CustomSentenceTransformerEmbeddings as CSTFM

st.set_page_config(page_title="AIì—ê²Œ ì§ˆë¬¸í•˜ê¸°", layout="wide")

FILLTERED_DOC_NUMBER = 5

#@st.cache_data
def load_embeddings():
    return CSTFM()

@st.cache_resource
def load_llm():
    project_root = Path(__file__).parent.parent
    env_path = project_root / '.env'
    load_dotenv(dotenv_path=env_path)
    
    baseurl = os.environ.get("BASE_URL")
    modelllm = os.environ.get("DEFAULT_LLMNAME")
    api_key = os.environ.get("API_KEY", "lm-studio")  # API í‚¤ë„ í™˜ê²½ ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜´

    if not all([baseurl, modelllm]):
        raise ValueError("í•„ìš”í•œ í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    chatllm = ChatOpenAI(
        base_url=baseurl,
        api_key=api_key,        
        model=modelllm,
        streaming=True,
        temperature=0,
    )
    
    return chatllm

class RAGChatAppUI:
    def __init__(self, app):
        try:
            self.app = app
            self.llm_name = "LM Studio"
            os.environ['STREAMLIT_CACHE_STORAGE_MANAGER'] = 'FileStorageManager'
            if 'messages' not in st.session_state:
                st.session_state.messages = []
            if 'search_results' not in st.session_state:
                st.session_state.search_results = []
            if 'chat_input_key' not in st.session_state:
                st.session_state.chat_input_key = f"chat_input_query_{int(time.time() * 1000)}"
        except Exception as e:
            error_message = f"_init_ ì˜¤ë¥˜ ë°œìƒ: {e}"
            st.error(error_message)

    def setup_main_ui(self):
        try:

            st.header("Ask your PDF, DOC, PPT, Excel, HWP ğŸ’¬")
            
            main_content = st.empty()
            with main_content.container():
                self.maincol1, self.maincol2 = st.columns([7, 3])
        except Exception as e:
            error_message = f"set_main_ui ì˜¤ë¥˜ ë°œìƒ: {e}"
            st.error(error_message)
            
    def set_llm_name(self, llm_name):
        self.llm_name =  llm_name

    def setup_sidebar(self):
        try:
            with st.sidebar:
                st.header("Rag Menu")
                tab1, tab2, tab3, tab4 = st.tabs(["Arg Chat", "ì„ë² ë”©", "ChromaDB ê´€ë¦¬", "LLM ëª¨ë¸"])
                
                with tab1:
                    self.setup_rag_chat_tab()
                with tab2:
                    self.setup_embed_tab()
                with tab3:
                    self.setup_chromadb_tab()
                with tab4:
                    self.setup_llmmodel_tab()
        except Exception as e:
            error_message = f"setup_sidebar ì˜¤ë¥˜ ë°œìƒ: {e}"
            st.error(error_message)

    def setup_rag_chat_tab(self):
        try:
            st.header("Arg Chat")
            st.session_state.rag_usage = st.radio("Ragì´ìš©ì—¬ë¶€ ğŸ‘‡", ["Rag+LLM", "LLM"], index=0 if st.session_state.rag_usage == "Rag+LLM" else 1)
            collections = self.app.db_manager.list_collections()
            selected_collection = st.selectbox("ê²€ìƒ‰í•  ì»¬ë ‰ì…˜ì„ ì„ íƒí•˜ì„¸ìš”", collections, key="search_collection_name")
            self.app.set_collection_name(selected_collection)
            self.setup_document_selection(selected_collection)
        except Exception as e:
            error_message = f"setup_arg_chat_tab ì˜¤ë¥˜ ë°œìƒ: {e}"
            st.error(error_message)

    def setup_document_selection(self, collection_name):
        try:
            st.subheader("ê²€ìƒ‰ëŒ€ìƒ ë¬¸ì„œì„ íƒ")
            source_search = st.text_input("ë¬¸ì„œê²€ìƒ‰:", key="source_search_input")
            
            if st.button("ê²€ìƒ‰"):
                st.session_state.filtered_sources = self.app.db_manager.get_all_documents_source(collection_name, source_search)
                st.session_state.show_search_results = True
            
            if st.session_state.show_search_results:
                with st.expander("ê²€ìƒ‰ ê²°ê³¼", expanded=True):
                    st.write("ë‹¤ìŒ ë¬¸ì„œë“¤ì´ ê²€ìƒ‰ë˜ì—ˆìŠµë‹ˆë‹¤. ì„ íƒí•˜ì„¸ìš”:")
                    for source in st.session_state.filtered_sources:
                        if st.checkbox(source, key=f"check_{source}"):
                            if source not in st.session_state.selected_sources:
                                st.session_state.selected_sources.append(source)
                        elif source in st.session_state.selected_sources:
                            st.session_state.selected_sources.remove(source)                
                    if st.button("ì„ íƒ ì™„ë£Œ"):
                        st.session_state.show_search_results = False
                        
            selected = st.multiselect(
                "ì„ íƒëœ ë¬¸ì„œ:", 
                options=st.session_state.filtered_sources,
                default=st.session_state.selected_sources,
                key="final_selected_sources",
            )
            
            st.session_state.selected_sources = selected
            
            col1, col2 = st.columns(2)
            with col1: 
                st.session_state.apply_filter = st.checkbox("ì ìš©", value=st.session_state.apply_filter)
            with col2:
                if st.button("í•„í„° ì´ˆê¸°í™”"):
                    st.session_state.selected_sources = []
                    st.session_state.filtered_sources = []
                    st.session_state.apply_filter = False
        except Exception as e:
            error_message = f"setup_document_collection ì˜¤ë¥˜ ë°œìƒ: {e}"
            st.error(error_message)

    def setup_embed_tab(self):
        try:
            st.header("ì„ë² ë”©")         
            collections = self.app.db_manager.list_collections()       
            selected_collection = st.selectbox("ì»¬ë ‰ì…˜ì„ ì„ íƒí•˜ì„¸ìš”", collections, key="embed_collection_select")
            
            if st.button("íŒŒì¼ ì—…ë¡œë” ì´ˆê¸°í™”"):
                st.session_state.files_processed = False
                st.rerun()

            if not st.session_state.files_processed:
                uploaded_files = st.file_uploader("íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”", type=['.pdf','.pptx','.ppt', \
                    '.doc', '.docx','.hwp','.hwpx','.xlsx','.md','.txt','html', '.htm'], accept_multiple_files=True)
                
                if st.button("ë²¡í„°ì €ì¥", key="store_vector_collection"):            
                    if uploaded_files is not None:                
                        total_chunks_stored = 0
                        for file in uploaded_files:
                            if self.app.db_manager.check_source_exists(selected_collection, file):
                                st.info(f"{file.name} íŒŒì¼ì´ DBì— ì´ë¯¸ ì¡´ì¬í•˜ì—¬ ì €ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                                time.sleep(5)
                            else:                            
                                try:
                                    with st.spinner(f"{file.name} íŒŒì¼ì˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘..."):
                                        text = self.app.db_manager.extract_text_from_file(
                                            file, file.name)
                                    
                                    if not text:
                                        st.warning(f"{file.name}ì—ì„œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
                                        continue

                                    with st.spinner(f"{file.name} í…ìŠ¤íŠ¸ ì²˜ë¦¬ ë° ì„ë² ë”© ì¤‘..."):
                                        processed_text = text
                                        chunks_stored = self.app.db_manager.split_embed_docs_store(
                                            processed_text, file.name, selected_collection)
                                    
                                    total_chunks_stored += chunks_stored
                                    st.success(f"'{file.name}' íŒŒì¼ì´ ì²˜ë¦¬ë˜ì–´ {chunks_stored}ê°œì˜ ì²­í¬ê°€ '{selected_collection}' ì»¬ë ‰ì…˜ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                                except Exception as e:
                                    st.error(f"{file.name} íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                                    time.sleep(5)
                        
                        st.success(f"ì´ {total_chunks_stored}ê°œì˜ ì²­í¬ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                        st.session_state.files_processed = True
                        st.rerun()
            else:
                st.success("íŒŒì¼ ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ìƒˆ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë ¤ë©´ 'íŒŒì¼ ì—…ë¡œë” ì´ˆê¸°í™”' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")
        except Exception as e:
            error_message = f"setup_embed_tab ì˜¤ë¥˜ ë°œìƒ: {e}"
            st.error(error_message)
                

    def setup_chromadb_tab(self):
        try:
            st.title("Arg Searchë¥¼ ìœ„í•œ ChromaDB ê´€ë¦¬ Section")
            management_menu = st.selectbox(
                "ì‘ì—…ì„ ì„ íƒí•˜ì„¸ìš”",
                ("Collection ìƒì„±", "Collection ì‚­ì œ", "Collection ë‚´ìš©ê²€ìƒ‰", "Collection ë‚´ìš©ë³´ê¸°"),
                key="tabmenu_select"
            )
            collections = self.app.db_manager.get_list_collections()
            
            if management_menu == "Collection ìƒì„±":
                self.create_collection_ui()
            elif management_menu == "Collection ì‚­ì œ":
                self.delete_collection_ui(collections)
            elif management_menu == "Collection ë‚´ìš©ê²€ìƒ‰":
                self.search_collection_ui(collections)
            elif management_menu == "Collection ë‚´ìš©ë³´ê¸°":
                self.view_collection_ui(collections)
        except Exception as e:
            error_message = f"Setup_embed_tab ì˜¤ë¥˜ ë°œìƒ: {e}"
            st.error(error_message)

    def create_collection_ui(self):
        try:
            st.header("ìƒˆ ì»¬ë ‰ì…˜ ìƒì„±")
            collection_name = st.text_input("ìƒì„±í•  ì»¬ë ‰ì…˜ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”")                
            if st.button("ìƒì„±", key="create_new_collection"):
                if collection_name not in self.app.db_manager.get_list_collections():
                    result = self.app.db_manager.create_collection(collection_name)
                    st.info(f"ì»¬ë ‰ì…˜ '{result}'ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
                else:
                    st.info(f"ì»¬ë ‰ì…˜ '{collection_name}'ì´ ì¡´ì¬í•˜ì—¬ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            error_message = f"create_collection_ui ì˜¤ë¥˜ ë°œìƒ: {e}"
            st.error(error_message)

    def delete_collection_ui(self, collections):
        try:
            st.header("ì»¬ë ‰ì…˜ ì‚­ì œ")
            if 'delete_state' not in st.session_state:
                st.session_state.delete_state = 'initial'

            selected_collection = st.selectbox("ì‚­ì œí•  ì»¬ë ‰ì…˜ì„ ì„ íƒí•˜ì„¸ìš”", collections, key="delete_collection_select")

            if st.button("ì‚­ì œ", key="delete_collection"):
                st.session_state.delete_state = 'confirm'
                        
            if st.session_state.delete_state == 'confirm':
                st.write(f"'{selected_collection}' ì»¬ë ‰ì…˜ì„ ì‚­ì œí•˜ì‹œê² ìŠµë‹ˆê¹Œ?")
                col1, col2 = st.columns(2)
                with col1:
                    if st.button("ì˜ˆ", key="confirm_yes"):
                        result = self.app.db_manager.delete_collection(selected_collection)
                        st.success(f"'{selected_collection}' ì»¬ë ‰ì…˜ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
                        st.session_state.delete_state = 'initial'
                        st.rerun()        
                            
                with col2:
                    if st.button("ì•„ë‹ˆì˜¤", key="confirm_no"):
                        st.info("ì‚­ì œê°€ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                        st.session_state.delete_state = 'initial'
                        st.rerun()        
        except Exception as e:
            error_message = f"delete_collection_ui ì˜¤ë¥˜ ë°œìƒ: {e}"
            st.error(error_message)

    def search_collection_ui(self, collections):
        try:
            st.header("ì»¬ë ‰ì…˜ ê²€ìƒ‰")
            selected_collection = st.selectbox("ê²€ìƒ‰í•  ì»¬ë ‰ì…˜ì„ ì„ íƒí•˜ì„¸ìš”", collections, key="search_collection_select")
            search_query = st.text_input("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”")
            if st.button("ê²€ìƒ‰", key="search_collectison_content"):
                results = self.app.db_manager.search_collection(selected_collection, search_query, self.app.db_manager.docnum)                
                self.display_search_results(results)  # self.app.display_search_results(results) ëŒ€ì‹ 
        except Exception as e:
            error_message = f"search_collection_ui ì˜¤ë¥˜ ë°œìƒ: {e}"
            st.error(error_message)


    def view_collection_ui(self, collections):
        try:
            st.header("ì»¬ë ‰ì…˜ ë‚´ìš©ë³´ê¸°")
            selected_collection = st.selectbox("ì»¬ë ‰ì…˜ì„ ì„ íƒí•˜ì„¸ìš”", collections, key="view_collection_select")            
            if st.button("ë‚´ìš© ë³´ê¸°", key="view_collection_content"):
                content = self.app.db_manager.view_collection_content(selected_collection)
                st.write(f"'{selected_collection}'ì˜ ë‚´ìš©ì…ë‹ˆë‹¤.")
                st.markdown(content)
        except Exception as e:
            error_message = f"view_collection_ui ì˜¤ë¥˜ ë°œìƒ: {e}"
            st.error(error_message)

    def setup_llmmodel_tab(self):
        try:
            llm_source = st.radio("LLM ì†ŒìŠ¤ ì„ íƒ:", ("LM Studio", "Ollama","Groq"))

            if llm_source == "Ollama":
                models = self.app.get_ollama_models()
                self.set_llm_name(llm_name="Ollama")
                if not models:
                    st.error("ì‚¬ìš© ê°€ëŠ¥í•œ Ollama ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. 'ollama pull' ëª…ë ¹ì–´ë¡œ ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œ í•´ì£¼ì„¸ìš”.")
                    self.app.set_llm_model(self.app.lm_llm)
                    return 

                selected_model = st.selectbox("ì‚¬ìš©í•  Ollama ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”:", models)
                st.write(f"ì„ íƒí•œ ëª¨ë¸: {selected_model}")

                llm = Ollama(model=selected_model)
                self.app.set_llm_model(llm)
            elif llm_source == "LM Studio":  # LM Studio
                models = self.app.get_lm_studio_models()       
                self.set_llm_name(llm_name="LM Studio")
                if models:
                    self.app.lm_llm.model_name = models
                    self.app.set_llm_model(self.app.lm_llm)
                    st.success("LM Studioì—ì„œ ë™ì¼í•œ ëª¨ë¸ì´ ì‹¤í–‰ë˜ê³  ìˆì–´ì•¼ ì •ìƒì ìœ¼ë¡œ ì‘ë™ë©ë‹ˆë‹¤.")
                else:
                    self.app.set_llm_model(self.app.lm_llm)
                    st.error("ë””í´íŠ¸ ì…‹íŒ…ì„ ë”°ë¦…ë‹ˆë‹¤.")
            else:
                models = self.app.load_groq()
                self.set_llm_name(llm_name="Groq")            
                if models:
                    self.app.lm_llm.model_name = models
                    self.app.set_llm_model(self.app.lm_llm)
                    st.success("Groq(ì™¸ë¶€API)ì„ ì´ìš©í•©ë‹ˆë‹¤.")
                else:
                    self.app.set_llm_model(self.app.lm_llm)
                    st.error("Groq(ì™¸ë¶€API)ë¥¼ .env íŒŒì¼ì˜ GROQ_API_KEYì— keyë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        except Exception as e:
            error_message = f"setup_llmmodel_tab ì˜¤ë¥˜ ë°œìƒ: {e}"
            st.error(error_message)
                    

    def display_chat_interface(self):
        try:
            with self.maincol1:           
                input_container = st.container()
                chat_history = st.container()
                # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
                with input_container:
                    user_question = st.chat_input("Enter your search query", key=st.session_state.chat_input_key)
                    if user_question:
                        st.session_state.messages.append(ChatMessage(role="user", content=user_question))
                        try:
                            asyncio.run(self.app.process_query_async(user_question))
                        except Exception as e:
                            st.error(f"An error occurred: {str(e)}")
                        self.update_chat_history(chat_history)
        except Exception as e:
            error_message = f"display_chat_interface ì˜¤ë¥˜ ë°œìƒ: {e}"
            st.error(error_message)
            
    def display_chat_messages(self):
        try:
            for message in st.session_state.messages[-8:]:  # ìµœì‹  4ê°œ ë©”ì‹œì§€ë§Œ í‘œì‹œ
                with st.chat_message(message.role):
                    st.markdown(message.content)
        except Exception as e:
            error_message = f"display_chat_messages ì˜¤ë¥˜ ë°œìƒ: {e}"
            st.error(error_message)
   
    def update_chat_history(self, chat_history):
        try:
            with chat_history:
                st.session_state.messages = st.session_state.messages[-8:]  # ìµœì‹  4ê°œ ë©”ì‹œì§€ë§Œ ìœ ì§€
                for message in reversed(st.session_state.messages):
                    if message.role == "user":
                        st.chat_message("user").write(message.content)
                    else:
                        st.chat_message("assistant").write(message.content)
        except Exception as e:
            error_message = f"update_chat_history ì˜¤ë¥˜ ë°œìƒ: {e}"
            st.error(error_message)
    

    def display_search_results(self, results):
        try:
            with self.maincol2:            
                if not results:
                    st.write("No results found.")
                else:
                    for i, result in enumerate(results, 1):
                        key = "view_" + str(i)
                        with st.expander(f"Result {i}"):
                            if isinstance(result, dict):
                                st.write(f"**Content:** {result['page_content']}")
                                st.write(f"**Metadata:** {result['metadata']}")
                                st.write(f"**Score:** {result['score']:.1f}")
                                if st.button(f"**File_name:** {result['metadata']['file_name']}", key=key):
                                    self.app.show_pdf(result['metadata']['file_name'])
                            else:
                                st.write(f"**Content:** {result.page_content}")
                                st.write(f"**Metadata:** {result.metadata}")
                                st.write(f"**Score:** {result.metadata.get('score', 'N/A'):.1f}")
                                if st.button(f"**File_name:** {result.metadata.get('file_name', 'Unknown')}", key=key):
                                    self.app.show_pdf(result.metadata.get('file_name'))
        except Exception as e:
            error_message = f"display_search_results ì˜¤ë¥˜ ë°œìƒ: {e}"
            st.error(error_message)
                

class RAGChatApp:
    def __init__(self):
        project_root = Path(__file__).parent.parent
        # .env íŒŒì¼ì˜ ê²½ë¡œ ì„¤ì •
        env_path = project_root / '.env'
        load_dotenv(dotenv_path=env_path)
        self.chromadb = ChromaDbManager()
        self.persist_directory = self.chromadb.get_persist_directory;
        self.collection_name = "rag_test"
        self.db_manager = self.chromadb
        self.lm_llm = load_llm()
        self.llm = self.lm_llm
        self.initialize_session_state()
        self.ui = RAGChatAppUI(self)
        os.environ["POSTHOG_DISABLED"] = "1"
        self.embeddings = load_embeddings()
        self.models = self.load_models_from_env("LM")
        self.groq = GroqManager()
        self.groq_models = self.load_models_from_env("GROQ")
        
    async def process_query_async(self, query):
        try:
            keyword, parsed_query = self.parse_input(query)
            if (keyword == "f" or st.session_state.apply_filter) and st.session_state.rag_usage == "Rag+LLM":
                await self.process_filtered_query_async(parsed_query)
            else:
                await self.process_regular_query_async(parsed_query)
        except Exception as e:
            error_message = f"process_query_async ì˜¤ë¥˜ ë°œìƒ: {e}"
            st.error(error_message)

    async def process_filtered_query_async(self, query):
        try:
            if st.session_state.selected_sources:
                docs = await asyncio.to_thread(self.db_manager.get_documents_by_source, 
                                            self.collection_name, st.session_state.selected_sources)
                if docs:
                    await self.generate_response_async(docs, query)
                else:
                    st.write("No documents found for the selected sources.")
            else:
                st.info("ê²€ìƒ‰í•  ë¬¸ì„œë¥¼ ì„ íƒí•˜ì„¸ìš”!")
        except Exception as e:
            error_message = f"process_filtered_query_async ì˜¤ë¥˜ ë°œìƒ: {e}"
            st.error(error_message)

    async def process_regular_query_async(self, query):
        try: 
            docs=[]
            if st.session_state.RagUsage == "Rag+LLM":
                with st.spinner('Rag+LLM ë‹µë³€ ì‚¬ì „ ì¤€ë¹„ì¤‘...'):
                    docs = await asyncio.to_thread(self.perform_search, query, self.db_manager, 
                                                self.collection_name, st.session_state.selected_sources)
                if docs:
                    await self.generate_response_async(docs, query)
                    self.ui.display_search_results(docs)
                else:
                    await self.fallback_to_llm_async(query)
            else:
                await self.generate_response_async(None, query)
        except Exception as e:
            error_message = f"process_regular_query_async ì˜¤ë¥˜ ë°œìƒ: {e}"
            st.error(error_message)

    async def generate_response_async(self, docs, query):
        try:
            
            chain = load_qa_chain(self.llm, chain_type="stuff", verbose=True)
            with st.spinner('AI ë‹µë³€ì„ ê¸°ë‹¤ë¦¬ê³  ìˆëŠ”ì¤‘...'):
                if self.ui.llm_name == "Groq":
                    docs_list = [docs] if isinstance(docs, str) else docs
                    response = GroqResponse(self.groq, docs_list, query)
                    content = response['content'] if isinstance(response['content'], str) else str(response['content'])
                    response = content
                else:
                    response = await asyncio.to_thread(chain.run, input_documents=docs or "", question=query)
                st.session_state.messages.append(ChatMessage(role="assistant", content=response))
               
                    
        except Exception as e:
            error_message = f"LLM ì„œë²„ì—°ê²° ì˜¤ë¥˜ ë°œìƒ: {e}"
            st.error(error_message)
            st.session_state.messages.append(ChatMessage(role="assistant", content=error_message))

    async def fallback_to_llm_async(self, query):
        st.info("ì„ íƒí•œ ì†ŒìŠ¤ë‚˜ ë¬¸ì„œì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ LLMì— ì§ˆì˜í•©ë‹ˆë‹¤.")
        await self.generate_response_async("", query)

    def initialize_session_state(self):
        try:
            if "messages" not in st.session_state:
                st.session_state.messages = []
            if "docs" not in st.session_state:
                st.session_state.docs = None
            if "selected_sources" not in st.session_state:
                st.session_state.selected_sources = []
            if "last_query" not in st.session_state:
                st.session_state.last_query = ""
            if "rag_usage" not in st.session_state:
                st.session_state.rag_usage = "Rag+LLM"
            if "max_docnum" not in st.session_state:
                st.session_state.max_docnum = 3
            if "apply_filter" not in st.session_state:
                st.session_state.apply_filter = False
            if "filtered_sources" not in st.session_state:
                st.session_state.filtered_sources = []
            if "RagUsage" not in st.session_state:    
                st.session_state.RagUsage = "Rag+LLM"
                
                    # ìƒˆë¡œìš´ ì´ˆê¸°í™” ì½”ë“œ ì¶”ê°€
            if "show_search_results" not in st.session_state:
                st.session_state.show_search_results = False
            if "files_processed" not in st.session_state:
                st.session_state.files_processed = False
        except Exception as e:
            error_message = f"initialize_session_state ì˜¤ë¥˜ ë°œìƒ: {e}"
            st.error(error_message)

    def set_collection_name(self, ragname):
        try:
            self.collection_name = ragname
        except Exception as e:
            error_message = f"set_collection_name ì˜¤ë¥˜ ë°œìƒ: {e}"
            st.error(error_message)

    def set_llm_model(self, modelname):
        try:
            self.llm = modelname
        except Exception as e:
            error_message = f"set_llm_model ì˜¤ë¥˜ ë°œìƒ: {e}"
            st.error(error_message)
            

    def get_ollama_models(self):
        try:
            result = subprocess.run(['ollama', 'list'], capture_output=True, text=True)
            lines = result.stdout.strip().split('\n')[1:]
            models = [line.split()[0] for line in lines]
            return models
        except Exception as e:
            error_message = f"get_ollama_models ì˜¤ë¥˜ ë°œìƒ: {e}"
            st.error(error_message)
    
    def load_groq(self):
        try:
            project_root = Path(__file__).parent.parent
            env_path = project_root / '.env'
            load_dotenv(dotenv_path=env_path)
            
            api_key = os.environ.get("GROQ_API_KEY")                            
            if not api_key:
                st.warning("GROQ_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                new_api_key = st.text_input("Groq API Key", type="password")
                if new_api_key:
                    # .env íŒŒì¼ì— API í‚¤ ì €ì¥
                    # .env íŒŒì¼ì˜ ê²½ë¡œë¥¼ ì§€ì •í•˜ì„¸ìš”
                    set_key(env_path, "GROQ_API_KEY", new_api_key)
                    st.success("API í‚¤ê°€ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ë‹¤ì‹œ ì‹œì‘í•´ì£¼ì„¸ìš”.")
                    st.stop()
                else:
                    st.error("API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                    return None

            available_models = self.get_groq_models()
            if not available_models:
                st.error("ì‚¬ìš© ê°€ëŠ¥í•œ Groq ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
                return None

            self.ui.set_llm_name(llm_name="Groq")
            
            # ì²« ë²ˆì§¸ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ì„ íƒ
            selected_model = available_models[0] if isinstance(available_models, list) else available_models
            self.lm_llm.model_name = selected_model
            self.set_llm_model(self.groq)

            try:
                groq_llm = ChatGroq(
                    groq_api_key=api_key,
                    model_name=selected_model,
                    temperature=0,
                )
                st.success(f"Groq ëª¨ë¸ '{selected_model}'ì´(ê°€) ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
                return groq_llm
            except Exception as e:
                st.error(f"Groq í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                return None

        except Exception as e:
            st.error(f"load_groq ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None
    
    def load_models_from_env(self,name):
        try:
            models = {}
            for key, value in os.environ.items():
                if name == "LM":
                    if key.startswith('LM_STUDIO_MODEL_'):
                        model_name = key.replace('LM_STUDIO_MODEL_', '')
                        models[model_name] = value
                if name == "GROQ":
                    if key.startswith('GROQ_MODEL_'):
                        model_name = key.replace('GROQ_MODEL_', '')
                        models[model_name] = value            
            return models
        except Exception as e:
            error_message = f"load_models_from_env ì˜¤ë¥˜ ë°œìƒ: {e}"
            st.error(error_message)

    def get_lm_studio_models(self):
        try:
            if not self.models:
                st.error("No LM Studio models defined in .env file.")
                return None

            selected_model = st.selectbox(
                "Select LM Studio Model",
                options=list(self.models.keys()),
                format_func=lambda x: f"{x} ({self.models[x]})"
            )

            if selected_model:
                model_id = self.models[selected_model]
                return model_id
            else:
                return None
        except Exception as e:
            error_message = f"get_llm_studio_modelsì˜¤ë¥˜ ë°œìƒ: {e}"
            st.error(error_message)
    
    def get_groq_models(self):
        try:
            if not self.groq_models:
                st.error("No Groq models defined in .env file.")
                return None

            selected_groqmodel = st.selectbox(
                "Select Groq Model",
                options=list(self.groq_models.keys()),
                format_func=lambda x: f"{x} ({self.groq_models[x]})"
            )

            if selected_groqmodel:
                model_id = self.groq_models[selected_groqmodel]
                return model_id
            else:
                return None
        except Exception as e:
            error_message = f"get_groq_models ì˜¤ë¥˜ ë°œìƒ: {e}"
            st.error(error_message)

    def parse_input(self, input_text):
        try:
            parts = input_text.split(']', 1)
            if len(parts) > 1 and parts[0].startswith('['):
                keyword = parts[0][1:].strip().lower()
                query = parts[1].strip()
                return keyword, query
            else:
                return None, input_text.strip()
        except Exception as e:
            error_message = f"parse_input ì˜¤ë¥˜ ë°œìƒ: {e}"
            st.error(error_message)


    def perform_search(self, query, db_manager, collection_name, selected_sources=None):
        try:
            raw_results = db_manager.search_collection(collection_name, query, n_results=FILLTERED_DOC_NUMBER)        
            if not raw_results:
                return []
            docs = []
            for result in raw_results:
                if not isinstance(result['page_content'], str):
                    result['page_content'] = str(result['page_content'])
                
                doc = Document(
                    # ì›ë³¸ textë¥¼ summarizeë¥¼ í•´ì„œ ë³´ë‚´ëŠ” ë°©ë²•-LLM ì†ë„ê°œì„  í…ŒìŠ¤íŠ¸
                    page_content=TextSummarizer.summarize(result['page_content'], 5),
                    # ì›ë³¸ textë¥¼ ê·¸ëŒ€ë¡œ ì „ë‹¬í•˜ëŠ” ë°©ë²•
                    # page_content=result['page_content'],
                    metadata={"score": result['score'], **result['metadata']}
                )            
                docs.append(doc)
            # ë””ë²„ê¹…ì„ ìœ„í•œ ì¶œë ¥
            #for doc in docs:
            #    print(doc.page_content)
                
            filtered_docs = [doc for doc in docs]
            
            if selected_sources:
                filtered_docs = [doc for doc in filtered_docs if doc.metadata.get('source', 'Unknown') in selected_sources]
            
            return filtered_docs
        except Exception as e:
            error_message = f"perform_search ì˜¤ë¥˜ ë°œìƒ: {e}"
            st.error(error_message)


    def process_query(self, query):
        try:
            keyword, parsed_query = self.parse_input(query)
            if (keyword == "f" or st.session_state.apply_filter) and st.session_state.rag_usage == "Rag+LLM":
                self.process_filtered_query(parsed_query)
            else:
                self.process_regular_query(parsed_query)
        except Exception as e:
            error_message = f"process_query ì˜¤ë¥˜ ë°œìƒ: {e}"
            st.error(error_message)

    def process_filtered_query(self, query):
        try:
            if st.session_state.selected_sources:
                docs = self.db_manager.get_documents_by_source(self.collection_name, st.session_state.selected_sources)
                if docs:
                    self.generate_response(docs, query)
                else:
                    st.write("No documents found for the selected sources.")
            else:
                st.info("ê²€ìƒ‰í•  ë¬¸ì„œë¥¼ ì„ íƒí•˜ì„¸ìš”!")
        except Exception as e:
            error_message = f"process_filtered_queryì˜¤ë¥˜ ë°œìƒ: {e}"
            st.error(error_message)

    def process_regular_query(self, query):
        try:
            if st.session_state.RagUsage == "Rag+LLM":
                with st.spinner('Rag+LLM ë‹µë³€ ì‚¬ì „ ì¤€ë¹„ì¤‘...'):
                    docs = self.perform_search(query, self.db_manager, self.collection_name, st.session_state.selected_sources)                
                if docs:
                    self.generate_response(docs, query)                
                    self.ui.display_search_results(docs)
                else:
                    self.fallback_to_llm(query)
            else:
                self.generate_response(None, query)            
        except Exception as e:
            error_message = f"process_regular_queryì˜¤ë¥˜ ë°œìƒ: {e}"
            st.error(error_message)
            
    def generate_response(self, docs, query):
        try:
            # Create the prompt template
            prompt_template = """
            System: You are an AI assistant that answers questions using only the provided information. Do not include any content not present in the given information. If the information is insufficient, say "I cannot answer with the given information."

            Context: {context}

            Human: {question}

            AI: """

            # Prepare the context from the retrieved documents
            context = "\n".join([doc.page_content for doc in docs])

            # Create the prompt
            prompt = prompt_template.format(context=context, question=query)

            # Load the QA chain
            chain = load_qa_chain(self.llm, chain_type="stuff", verbose=True)

            with st.spinner('AI ë‹µë³€ì„ ê¸°ë‹¤ë¦¬ê³  ìˆëŠ”ì¤‘...'):
                # Run the chain with the prepared prompt
                response = chain.run(input_documents=docs or "", question=prompt)
                st.session_state.messages.append(ChatMessage(role="assistant", content=response))
        except Exception as e:
            error_message = f"LLM ì„œë²„ì—°ê²° ì˜¤ë¥˜ ë°œìƒ: {e}"
            st.error(error_message)
            st.session_state.messages.append(ChatMessage(role="assistant", content=error_message))            

    
    def fallback_to_llm(self, query):
        try:
            st.info("ì„ íƒí•œ ì†ŒìŠ¤ë‚˜ ë¬¸ì„œì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ LLMì— ì§ˆì˜í•©ë‹ˆë‹¤.")
            self.generate_response(None, query)
        except Exception as e:
            error_message = f"fallback_to_llm ì˜¤ë¥˜ ë°œìƒ: {e}"
            st.error(error_message)

    def show_pdf(self, file_path):
        try:
            file_path = os.path.join(self.persist_directory, file_path)
            with open(file_path, "rb") as f:
                base64_pdf = base64.b64encode(f.read()).decode('utf-8')
            pdf_display = f'<iframe src="data:application/pdf;base64,{base64_pdf}" width="800" height="800" type="application/pdf"></iframe>'
            st.markdown(pdf_display, unsafe_allow_html=True)
        except Exception as e:
            error_message = f"show_pdf ì˜¤ë¥˜ ë°œìƒ: {e}"
            st.error(error_message)

    def run(self):
        try:
            self.ui.setup_main_ui()
            with st.sidebar:
                self.ui.setup_sidebar()
            self.ui.display_chat_interface()
        except Exception as e:
            error_message = f"run ì˜¤ë¥˜ ë°œìƒ: {e}"
            st.error(error_message)
        
if __name__ == '__main__':
    if platform.system() != 'Windows':
        print("ì´ ì• í”Œë¦¬ì¼€ì´ì…˜ì€ Windowsì—ì„œë§Œ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    app = RAGChatApp()
    app.run()
    